{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Lane Lines on the Road\n",
    "\n",
    "---\n",
    "\n",
    "Prof. Dr.-Ing. Antje Muntzinger, Hochschule f√ºr Technik Stuttgart\n",
    "\n",
    "antje.muntzinger@hft-stuttgart.de\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE:** You may answer in English or German.\n",
    "\n",
    "The following notebook is based on Udacity's *Self-Driving Car Nanodegree*.\n",
    "\n",
    "In this project, you will use the tools you learned about in the lesson to identify lane lines on the road.  You can develop your pipeline on a series of individual images, and later apply the result to a video stream (really just a series of images). Check out the video clip \"raw-lines-example.mp4\" (also contained in this repository) to see what the output should look like after using the helper functions below. \n",
    "\n",
    "Once you have a result that looks roughly like \"raw-lines-example.mp4\", you'll need to get creative and try to average and/or extrapolate the line segments you've detected to map out the full extent of the lane lines.  You can see an example of the result you're going for in the video \"final-result-example.mp4\".  Ultimately, you would like to draw just one line for the left side of the lane, and one for the right.\n",
    "\n",
    "Let's have a look at our first image called 'test_images/solidWhiteRight.jpg'.  Run the 2 cells below to display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "plt.imshow(image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect Line Segments using Canny and Hough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first goal is to detect white or yellow lane markings. The tools you have are color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Transform line detection.  You  are also free to explore and try other techniques that were not presented in the lesson.  Your goal is piece together a pipeline to detect the line segments in the image. Your output should look something like this after detecting line segments:\n",
    "\n",
    "\n",
    "<figure>\n",
    " <img src=\"examples\\\\line-segments-example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\">  </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some OpenCV functions (beyond those introduced in the lesson) that might be useful for this project are:**\n",
    "\n",
    "`cv2.inRange()` for color selection  \n",
    "\n",
    "`cv2.fillPoly()` for regions selection  \n",
    "\n",
    "`cv2.line()` to draw lines on an image given endpoints  \n",
    "\n",
    "`cv2.addWeighted()` to coadd / overlay two images \n",
    "\n",
    "`cv2.cvtColor()` to grayscale or change color \n",
    "\n",
    "`cv2.imwrite()` to output images to file  \n",
    "\n",
    "`cv2.bitwise_and()` to apply a mask to an image \n",
    "\n",
    "**Check out the OpenCV documentation to learn about these!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions to help get you started. They should look familiar from the lesson!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 1) Build a pipeline to detect line segments using Canny edge detection and Hough transform. Run your solution on all test_images.\n",
    "Try tuning the various parameters, especially the low and high Canny thresholds as well as the Hough lines parameters. Plot the edges, Hough lines and detected lane segments in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the test images:\n",
    "import os\n",
    "os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 2a) Implement the `process_image` function below: It should call your hough pipeline on each image and return an image where the hough results are visible in the original photo. **(2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to process each frame of the video\n",
    "def process_image(img):\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    img_lanes = img.copy() # placeholder for the final image\n",
    "\n",
    "    return img_lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 2b) How do you interpret your video results? How is the overall performance, do you see some remaining problems? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpolating Line Segments \n",
    "\n",
    "At this point, if you were successful with making the pipeline and tuning parameters, you probably have the Hough line segments drawn onto the road, but what about identifying the full extent of the lane and marking it clearly as in the example video (final-result-example.mp4)?  Think about defining a line to run the full length of the visible lane based on the line segments you identified with the Hough Transform. Try to average and/or extrapolate the line segments you've detected to map out the full extent of the lane lines. You can see an example of the result you're going for in the video \"final-result-example.mp4\".\n",
    "\n",
    "Your output should now look something like this after detecting line segments:\n",
    "\n",
    "<figure>\n",
    " <img src=\"examples\\\\line-segments-example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\">  </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "Now the next goal is to connect/average/extrapolate line segments to get output like this:\n",
    "<figure>\n",
    " <img src=\"examples\\\\laneLines_thirdPass.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 3) Complete the code below. \n",
    "    \n",
    "a) Complete the function `get_y_intercept_slope` by calculating the average y-intercept and slope of all inputs\n",
    "    \n",
    "b) Complete the function `get_x` by calculating the x-coordinates of $y_1$ and $y_2$.\n",
    "    \n",
    "**(6 points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# Get average y-intercept and average slope of the lines\n",
    "def get_y_intercept_slope(lane_lines, slopes):\n",
    "    '''Inputs:\n",
    "    lane_lines: array of lines detected by Hough transform\n",
    "    slopes: array of slopes of the lines detected by Hough transform\n",
    "    Outputs:\n",
    "    avg_intercept: average y-intercept of the lines\n",
    "    avg_slope: average slope of the lines\n",
    "    '''\n",
    "\n",
    "    # Remove NaN and Inf values from slopes\n",
    "    slopes = slopes[~np.isnan(slopes)]\n",
    "    slopes = slopes[~np.isinf(slopes)]\n",
    "\n",
    "    # Reshape the lines from (N, 4) to (N*2, 2)\n",
    "    # where N is the number of lines and 4 is the number of coordinates for each line\n",
    "    # The first two coordinates are the start points and the last two are the end points: (x1, y1, x2, y2)\n",
    "    # The reshape will give us (N*2, 2) where the first column is x and the second column is y\n",
    "    lane_lines = lane_lines.reshape((lane_lines.shape[0]*2, lane_lines.shape[1]//2)) \n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "\n",
    "    return avg_intercept, avg_slope\n",
    "\n",
    "# Get x values for a line given y values, slope and y-intercept\n",
    "def get_x(y_1, y_2, slope, b):\n",
    "    '''Inputs:\n",
    "    y_1: y-coordinate of the first point\n",
    "    y_2: y-coordinate of the second point\n",
    "    slope: slope of the line\n",
    "    b: y-intercept of the line\n",
    "    Outputs:    \n",
    "    x_1: x-coordinate of the first point\n",
    "    x_2: x-coordinate of the second point\n",
    "    '''\n",
    "\n",
    "    if np.isnan(slope) or np.isnan(b) or np.isinf(slope) or np.isinf(b):\n",
    "        # If slope or y-intercept is NaN or Inf, return 0\n",
    "        x_1 = x_2 = 0\n",
    "    else:\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "        \n",
    "    \n",
    "    return x_1, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extrapolate detected Hough lines\n",
    "def extrapolate_lines(img, lines, plot=True, color=[255, 0, 0], thickness=10):\n",
    "    img_hough_lines_extrapolated = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8) # Create a blank image\n",
    "\n",
    "    lines = lines.reshape((lines.shape[0], lines.shape[2])) # Reshape to 2D array of x1,y1,x2,y2\n",
    "    y_min = lines.reshape((lines.shape[0]*2, lines.shape[1]//2))[:,1].min() # Get the minimum y value from all lines\n",
    "\n",
    "    # Get the slopes of the lines\n",
    "    # slope= (    y2      -     y1   )/(    x2     -     x1    )  \n",
    "    slopes = (lines[:,3] - lines[:,1])/(lines[:,2] - lines[:,0]) # Calculate slope for each line\n",
    "    slopes = slopes[~np.isinf(slopes)]\n",
    "    slopes = slopes[~np.isnan(slopes)]\n",
    "    \n",
    "    # Get the left and right lines based on slope\n",
    "    left_lines = lines[slopes < -0.5]   # Left  lines should have negative slope, threshold=-0.5 (because y-axis is inverted)\n",
    "    right_lines= lines[slopes > 0.5]   # Right lines should have positive slope, threshold=+0.5\n",
    "    left_slopes = slopes[slopes < -0.5]\n",
    "    right_slopes= slopes[slopes > 0.5]\n",
    "    \n",
    "    # Get average y-intercept and average slope\n",
    "    left_b, left_avg_m = get_y_intercept_slope(left_lines, left_slopes) \n",
    "    right_b, right_avg_m = get_y_intercept_slope(right_lines, right_slopes)\n",
    "\n",
    "    # using y_min, avg_slope and y_intercept find points x1, x2 that will be used to draw the lines\n",
    "    left_x1, left_x2 = get_x(y_1=y_min, y_2=img_hough_lines_extrapolated.shape[0], slope=left_avg_m, b=left_b)\n",
    "    right_x1, right_x2 = get_x(y_1=y_min, y_2=img_hough_lines_extrapolated.shape[0], slope=right_avg_m, b=right_b)\n",
    "\n",
    "    # Draw the lines \n",
    "    cv2.line(img_hough_lines_extrapolated, (int(left_x1), int(y_min)), (int(left_x2), img_hough_lines_extrapolated.shape[0]), color, thickness)\n",
    "    cv2.line(img_hough_lines_extrapolated, (int(right_x1), int(y_min)), (int(right_x2), img_hough_lines_extrapolated.shape[0]), color, thickness)\n",
    "\n",
    "    # Add extrapolated Hough lines to original image\n",
    "    # the result image is computed as follows:\n",
    "    # initial_img * alpha + img * beta + gamma\n",
    "    alpha=0.8\n",
    "    beta=1.\n",
    "    gamma=0.\n",
    "    img_lanes_extrapolated = cv2.addWeighted(img_hough_lines_extrapolated, alpha, img, beta, gamma)\n",
    "    if plot:\n",
    "        plt.imshow(img_lanes_extrapolated)\n",
    "        plt.show()\n",
    "    return img_lanes_extrapolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over test images and apply the pipeline\n",
    "for img_name in os.listdir(\"test_images/\"):\n",
    "    print(\"Processing image: \", img_name)\n",
    "    img = mpimg.imread(\"test_images/\" + img_name)\n",
    "    print(\"Line segments detected using Hough transform:\")\n",
    "    img_masked_edges, img_lanes, lines = hough_pipeline(img, plot=True)\n",
    "    print(\"Line segments extrapolated:\")\n",
    "    img_lanes_extrapolated = extrapolate_lines(img, lines, plot=True, color=[255, 0, 0], thickness=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating Improved Videos\n",
    "\n",
    "As before, test your solution on the two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 4a) Implement the `process_image_extrapolated` function below: It should call your hough pipeline on each image and return an image where the extrapolated hough results are visible in the original photo. **(3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each frame of the video\n",
    "def process_image_extrapolated(img):\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "    img_lanes_extrapolated = img.copy() # placeholder for the final image\n",
    "\n",
    "    return img_lanes_extrapolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output2 = 'test_videos_output/solidWhiteRight2.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# clip3 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip3 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip2 = clip3.fl_image(process_image_extrapolated) #NOTE: this function expects color images!\n",
    "%time white_clip2.write_videofile(white_output2, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the one with the solid yellow lane on the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output2 = 'test_videos_output/solidYellowLeft2.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# clip4 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip4 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip2 = clip4.fl_image(process_image_extrapolated)\n",
    "%time yellow_clip2.write_videofile(yellow_output2, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** 4b) How do you interpret your video results? How is the overall performance, do you see some remaining problems? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflections\n",
    "\n",
    "**TODO:** 5) Congratulations on finding the lane lines!  As the final step in this project, please share your thoughts on your lane finding pipeline. Specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail? Please add your thoughts below! **(2 points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Converting this Jupyter Notebook to pdf is difficult due to the videos, so it is sufficient to submit the .ipynb file for this project."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
